"""
This module defines the `AgentService` class and a preconfigured instance
`agent_service` for orchestrating AI agent execution and streaming results.

Key Responsibilities:
    - Provide an asynchronous interface for invoking the agent orchestration graph.
    - Stream agent outputs (text or image) to clients in Server-Sent Events (SSE) format.
    - Integrate context such as user ID, session, dataset summaries, and storage URI
      into the agent execution workflow.

Classes:
    AgentService: Service layer exposing methods to invoke the agent orchestration
                  graph and stream results in real time.
    agent_service: Preconfigured global instance of `AgentService` using the
                   default `agents_orchestrator`.
"""

import json
from typing import Any
from uuid import UUID


from pydantic import BaseModel
from sqlalchemy.orm import Session


from agents.graphs.orchestrator import agents_orchestrator


class AgentService(BaseModel):
    """
    Service layer for orchestrating agent execution and streaming responses.

    Responsibilities:
        - Wrap the `agents_orchestrator` graph for easy invocation.
        - Stream intermediate or final results back to clients via SSE.
        - Handle both textual and image outputs from the agents.
    """

    agents_orchestrator: Any

    async def stream(
        self,
        question: str,
        db: Session,
        user_id: int,
        file_name: str,
        session_id: UUID,
        storage_uri: str,
        dataset_summary: str,
    ):
        """
        Asynchronously stream agent responses as SSE-compatible JSON messages.

        This method interacts with the agent orchestration graph, yielding
        results as they are produced. Supports two output types:
            - "text": chunks of text from the chat model.
            - "image": image content generated by visualization agents.

        Args:
            question: User query or instruction.
            db: Active SQLAlchemy session.
            user_id : Unique identifier for the user.
            file_name: File associated with the request.
            session_id: Unique identifier for the interaction session.
            storage_uri: URI to external storage (S3, GCS, etc.).
            dataset_summary: Pre-computed summary of dataset for agent reasoning.

        Yields:
            str: SSE-formatted JSON strings:
                {"type": "text", "data": "<text chunk>"}
                {"type": "image", "data": "<image content>"}
        """
        async for chunk in self.agents_orchestrator.astream_events(
            {
                "question": question,
                "db": db,
                "user_id": user_id,
                "file_name": file_name,
                "session_id": session_id,
                "storage_uri": storage_uri,
                "dataset_summary": dataset_summary,
            },
            config={"recursion_limit": 100},
        ):
            # Handle image outputs when the chain ends and output exists
            if (
                chunk["metadata"].get("image", False)
                and chunk["event"] == "on_chain_end"
                and chunk["data"].get("output", False)
            ):
                data = chunk["data"]["output"].content
                yield f"data: {json.dumps({'type': 'image', 'data': data})}\n\n"

            # Handle text streaming from the chat model
            if chunk["event"] == "on_chat_model_stream":
                stream = chunk["metadata"].get("stream", True)
                if stream:
                    data = chunk["data"]["chunk"].content
                    yield f"data: {json.dumps({'type': 'text', 'data': data})}\n\n"


# Global preconfigured service instance
agent_service = AgentService(agents_orchestrator=agents_orchestrator)
